{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5084161,"sourceType":"datasetVersion","datasetId":2952181}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \n\nimport os\nfor dirname, _, filenames in os.walk('./archive'):\n    print(dirname)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T12:59:39.605458Z","iopub.execute_input":"2025-04-18T12:59:39.605734Z","iopub.status.idle":"2025-04-18T12:59:39.913581Z","shell.execute_reply.started":"2025-04-18T12:59:39.605712Z","shell.execute_reply":"2025-04-18T12:59:39.913003Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torchvision.transforms as transforms\nfrom PIL import Image\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport segmentation_models_pytorch as smp\nfrom pathlib import Path\n\n\n# --- Configuration ---\nENCODER='resnext101_32x16d'\nENCODER_WEIGHTS = 'instagram' \nN_CLASSES = 1\nACTIVATION = 'sigmoid' \nDATA_DIR = Path(\"/kaggle/input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/\")\nINPUT_SIZE = (256, 256)\nDEVICE= 'cuda' if torch.cuda.is_available() else 'cpu'\nDEVICE","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T13:01:15.849488Z","iopub.execute_input":"2025-04-18T13:01:15.850224Z","iopub.status.idle":"2025-04-18T13:01:15.857690Z","shell.execute_reply.started":"2025-04-18T13:01:15.850194Z","shell.execute_reply":"2025-04-18T13:01:15.856965Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"imagenet_mean = [0.485, 0.456, 0.406]\nimagenet_std = [0.229, 0.224, 0.225]\n    \ntransform=transforms.Compose([\n    transforms.Resize(INPUT_SIZE),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=imagenet_mean,std=imagenet_std)\n])\ndef image_tensor(img_path):\n    img_pil = Image.open(img_path).convert(\"RGB\")\n    return transform(img_pil).unsqueeze(0) # shape [1, C, H, W]\n\nmask_transform = transforms.Compose([\n    transforms.Resize(INPUT_SIZE),\n    transforms.ToTensor()  # Converts to [0, 1] float tensor\n])\ndef mask_tensor(mask_path):\n    mask_pil = Image.open(mask_path).convert('L')  # grayscale\n    mask = mask_transform(mask_pil)\n    mask = (mask > 0.5).float()\n    return mask.unsqueeze(0)\n\n\ndef dice_loss(pred_mask, actual_mask, smooth=1e-6):\n    pred_flat = pred_mask.view(-1)\n    actual_flat = actual_mask.view(-1)\n    \n    intersection = (pred_flat * actual_flat).sum()\n    dice = (2. * intersection + smooth) / (pred_flat.sum() + actual_flat.sum() + smooth)\n    \n    return 1 - dice","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T12:59:57.338908Z","iopub.execute_input":"2025-04-18T12:59:57.339228Z","iopub.status.idle":"2025-04-18T12:59:57.347085Z","shell.execute_reply.started":"2025-04-18T12:59:57.339204Z","shell.execute_reply":"2025-04-18T12:59:57.346374Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"IMAGE_PATH=DATA_DIR/\"benign/benign (10).png\"\nimg_pil = Image.open(IMAGE_PATH).convert(\"RGB\")\n\nMASK_PATH=DATA_DIR/\"benign/benign (10)_mask.png\"\nout_img_pil = Image.open(MASK_PATH).convert(\"L\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T13:00:03.057270Z","iopub.execute_input":"2025-04-18T13:00:03.058033Z","iopub.status.idle":"2025-04-18T13:00:03.091105Z","shell.execute_reply.started":"2025-04-18T13:00:03.058005Z","shell.execute_reply":"2025-04-18T13:00:03.090591Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.utils.data import Dataset\nfrom pathlib import Path\nfrom PIL import Image\nimport torch\n\n# Assuming image_tensor and mask_tensor are already defined\n# and INPUT_SIZE, imagenet_mean/std are declared outside this class.\n\nclass BUSI(Dataset):\n    def __init__(self, data_dir):\n        self.data_dir = Path(data_dir)\n        self.images = []\n        self.masks = []\n\n        subDirs = ['benign', 'malignant', 'normal']\n        print(f\"Scanning folders: {subDirs} in {self.data_dir}\")\n\n        for subdir in subDirs:\n            classDir = self.data_dir / subdir\n            if not classDir.is_dir():\n                print(f\"Path Problem {classDir}\")\n                continue\n\n            for file in classDir.glob('*.png'):\n                if not file.name.endswith('_mask.png'):\n                    maskPath = file.parent / (file.stem + '_mask.png')\n                    if maskPath.exists():\n                        # Use your predefined functions\n                        image = image_tensor(file)\n                        mask = mask_tensor(maskPath)\n                        self.images.append(image.squeeze(0))  # Remove batch dim\n                        self.masks.append(mask.squeeze(0))    # Remove batch dim\n                    else:\n                        print(f\"Path Problem {maskPath}\")\n        \n        print(f\"Found {len(self.images)} image-mask pairs.\")\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.item()\n        return {\n            'image': self.images[idx],  # shape: [3, H, W]\n            'mask': self.masks[idx]     # shape: [1, H, W]\n        }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T13:00:04.555337Z","iopub.execute_input":"2025-04-18T13:00:04.555903Z","iopub.status.idle":"2025-04-18T13:00:04.563033Z","shell.execute_reply.started":"2025-04-18T13:00:04.555879Z","shell.execute_reply":"2025-04-18T13:00:04.562345Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset = BUSI(DATA_DIR)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T13:00:17.089266Z","iopub.execute_input":"2025-04-18T13:00:17.090016Z","iopub.status.idle":"2025-04-18T13:00:29.248712Z","shell.execute_reply.started":"2025-04-18T13:00:17.089987Z","shell.execute_reply":"2025-04-18T13:00:29.248002Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.utils.data import random_split, DataLoader\n\ntest_ratio = 0.2\ndataset_size = len(dataset)\ntest_size = int(test_ratio * dataset_size)\ntrain_size = dataset_size - test_size\n\n# Split the dataset\ntrain_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n\n# Create DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T13:00:32.642213Z","iopub.execute_input":"2025-04-18T13:00:32.643316Z","iopub.status.idle":"2025-04-18T13:00:32.650564Z","shell.execute_reply.started":"2025-04-18T13:00:32.643285Z","shell.execute_reply":"2025-04-18T13:00:32.649555Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for batch in train_loader:\n    images = batch['image']  # shape: [B, 3, H, W]\n    masks = batch['mask']    # shape: [B, 1, H, W]\n    print(images.shape, masks.shape)\n    break\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T13:00:34.537915Z","iopub.execute_input":"2025-04-18T13:00:34.538544Z","iopub.status.idle":"2025-04-18T13:00:34.547340Z","shell.execute_reply.started":"2025-04-18T13:00:34.538519Z","shell.execute_reply":"2025-04-18T13:00:34.546697Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = smp.Unet(\n            encoder_name=ENCODER,\n            encoder_weights=\"instagram\",\n            in_channels=3,\n            classes=1,\n            activation=ACTIVATION\n         )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T13:01:21.522686Z","iopub.execute_input":"2025-04-18T13:01:21.523288Z","iopub.status.idle":"2025-04-18T13:01:35.429115Z","shell.execute_reply.started":"2025-04-18T13:01:21.523263Z","shell.execute_reply":"2025-04-18T13:01:35.428312Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tqdm import tqdm\nimport copy\nimport torch.optim as optim\n\n# Define weights for train and test loss\nTRAIN_LOSS_WEIGHT = 0.2\nTEST_LOSS_WEIGHT = 0.8\n\n# --- Training Configuration ---\nEPOCHS = 20\nLEARNING_RATE = 1e-4\nCHECKPOINT_PATH = \"./best_model.pth\"\n\n# Define optimizer and loss function\noptimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\ncriterion = dice_loss\n\n# Training loop\nbest_combined_loss = float('inf')\nbest_model_wts = copy.deepcopy(model.state_dict())\n\nmodel.to(DEVICE)\nfor epoch in range(EPOCHS):\n    print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n    \n    # Training phase\n    model.train()\n    train_loss = 0.0\n    train_loader_tqdm = tqdm(train_loader, desc=\"Training\", leave=False)\n    for batch in train_loader_tqdm:\n        images = batch['image'].to(DEVICE)\n        masks = batch['mask'].to(DEVICE)\n\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, masks)\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n        train_loader_tqdm.set_postfix(loss=loss.item())\n\n    avg_train_loss = train_loss / len(train_loader)\n    print(f\"Epoch {epoch + 1} Train Loss: {avg_train_loss:.4f}\")\n\n    # Validation phase (test loss)\n    model.eval()\n    test_loss = 0.0\n    with torch.no_grad():\n        for batch in test_loader:\n            images = batch['image'].to(DEVICE)\n            masks = batch['mask'].to(DEVICE)\n            outputs = model(images)\n            loss = criterion(outputs, masks)\n            test_loss += loss.item()\n\n    avg_test_loss = test_loss / len(test_loader)\n    print(f\"Epoch {epoch + 1} Test Loss: {avg_test_loss:.4f}\")\n\n    # Calculate combined loss\n    combined_loss = (TRAIN_LOSS_WEIGHT * avg_train_loss) + (TEST_LOSS_WEIGHT * avg_test_loss)\n\n    # Save the best model if combined loss is lower\n    if combined_loss < best_combined_loss:\n        best_combined_loss = combined_loss\n        best_model_wts = copy.deepcopy(model.state_dict())\n        torch.save(model.state_dict(), CHECKPOINT_PATH)\n        print(f\"Best model saved with Combined Loss: {combined_loss:.4f} (Train Loss: {avg_train_loss:.4f}, Test Loss: {avg_test_loss:.4f})\")\n\n# Load the best model weights\nmodel.load_state_dict(best_model_wts)\nprint(\"Training complete. Best model loaded.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T13:01:38.060815Z","iopub.execute_input":"2025-04-18T13:01:38.061444Z","iopub.status.idle":"2025-04-18T13:26:39.972595Z","shell.execute_reply.started":"2025-04-18T13:01:38.061414Z","shell.execute_reply":"2025-04-18T13:26:39.971751Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, jaccard_score\nimport numpy as np\n\ndef compute_iou(preds, labels):\n    preds = preds.astype(bool)\n    labels = labels.astype(bool)\n    \n    intersection = np.logical_and(preds, labels).sum()\n    union = np.logical_or(preds, labels).sum()\n    \n    if union == 0:\n        return 1.0 if intersection == 0 else 0.0\n    return intersection / union\n\ndef compute_dice(preds, labels):\n    preds = preds.astype(bool)\n    labels = labels.astype(bool)\n    \n    intersection = np.logical_and(preds, labels).sum()\n    pred_sum = preds.sum()\n    label_sum = labels.sum()\n    \n    if pred_sum + label_sum == 0:\n        return 1.0\n    return (2.0 * intersection) / (pred_sum + label_sum)\n\ndef evaluate_model(model, test_loader, device):\n    model.to(device)\n    model.eval()\n    \n    total_loss = 0.0\n    all_preds = []\n    all_labels = []\n    \n    with torch.no_grad():\n        for batch in test_loader:\n            images = batch['image'].to(device)  # [B, 3, H, W]\n            masks = batch['mask'].to(device)    # [B, 1, H, W]\n            \n            # Forward pass\n            outputs = model(images)  # [B, 1, H, W]\n            loss = dice_loss(outputs, masks)\n            total_loss += loss.item()\n            \n            # Threshold predictions\n            predictions = (outputs > 0.5).float()\n            \n            # Flatten predictions and labels for metric calculation\n            all_preds.extend(predictions.cpu().numpy().flatten())\n            all_labels.extend(masks.cpu().numpy().flatten())\n    \n    # Convert to numpy arrays\n    all_preds = np.array(all_preds)\n    all_labels = np.array(all_labels)\n    \n    # Calculate metrics\n    avg_loss = total_loss / len(test_loader)\n    accuracy = accuracy_score(all_labels, all_preds)\n    precision = precision_score(all_labels, all_preds, zero_division=0)\n    recall = recall_score(all_labels, all_preds, zero_division=0)\n    f1 = f1_score(all_labels, all_preds, zero_division=0)\n    iou = compute_iou(all_preds, all_labels)\n    dice = compute_dice(all_preds, all_labels)\n    \n    print(f\"Test Loss: {avg_loss:.4f}\")\n    print(f\"Accuracy: {accuracy:.4f}\")\n    print(f\"Precision: {precision:.4f}\")\n    print(f\"Recall: {recall:.4f}\")\n    print(f\"F1 Score: {f1:.4f}\")\n    print(f\"IoU: {iou:.4f}\")\n    print(f\"Dice Coefficient: {dice:.4f}\")\n    \n    return avg_loss, accuracy, precision, recall, f1, iou, dice","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T13:26:52.748384Z","iopub.execute_input":"2025-04-18T13:26:52.748990Z","iopub.status.idle":"2025-04-18T13:26:53.355299Z","shell.execute_reply.started":"2025-04-18T13:26:52.748964Z","shell.execute_reply":"2025-04-18T13:26:53.354688Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Load the trained model\nmodel.load_state_dict(torch.load(CHECKPOINT_PATH))\nmodel.eval()\n\n# Function to visualize images, masks, and predictions\ndef visualize_predictions(model, test_loader, device, num_samples=5):\n    model.to(device)\n    model.eval()\n    \n    samples = 0\n    with torch.no_grad():\n        for batch in test_loader:\n            images = batch['image'].to(device)  # [B, 3, H, W]\n            masks = batch['mask'].to(device)    # [B, 1, H, W]\n            predictions = model(images)        # [B, 1, H, W]\n            \n            predictions = (predictions > 0.5).float()  # Threshold predictions\n            \n            for i in range(images.size(0)):\n                if samples >= num_samples:\n                    return\n                \n                # Convert tensors to numpy arrays for visualization\n                image_np = images[i].cpu().permute(1, 2, 0).numpy()\n                mask_np = masks[i].cpu().squeeze(0).numpy()\n                pred_np = predictions[i].cpu().squeeze(0).numpy()\n                \n                # Denormalize the image\n                image_np = image_np * np.array(imagenet_std) + np.array(imagenet_mean)\n                image_np = np.clip(image_np, 0, 1)\n                \n                # Plot the image, ground truth mask, and predicted mask\n                plt.figure(figsize=(12, 4))\n                plt.subplot(1, 3, 1)\n                plt.imshow(image_np)\n                plt.title(\"Image\")\n                plt.axis(\"off\")\n                \n                plt.subplot(1, 3, 2)\n                plt.imshow(mask_np, cmap=\"gray\")\n                plt.title(\"Ground Truth Mask\")\n                plt.axis(\"off\")\n                \n                plt.subplot(1, 3, 3)\n                plt.imshow(pred_np, cmap=\"gray\")\n                plt.title(\"Predicted Mask\")\n                plt.axis(\"off\")\n                \n                plt.show()\n                \n                samples += 1\n\n# Visualize predictions\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T13:27:01.971536Z","iopub.execute_input":"2025-04-18T13:27:01.971984Z","iopub.status.idle":"2025-04-18T13:27:02.730754Z","shell.execute_reply.started":"2025-04-18T13:27:01.971964Z","shell.execute_reply":"2025-04-18T13:27:02.730175Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model2 = smp.Unet(\n            encoder_name=ENCODER,\n            encoder_weights=\"instagram\",\n            in_channels=3,\n            classes=1,\n            activation=ACTIVATION\n         )\nmodel2.load_state_dict(torch.load(\"best_model.pth\"))\nevaluate_model(model2, test_loader, DEVICE)\nvisualize_predictions(model2, test_loader, DEVICE, num_samples=10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T13:42:21.684772Z","iopub.execute_input":"2025-04-18T13:42:21.685275Z","iopub.status.idle":"2025-04-18T13:43:07.815591Z","shell.execute_reply.started":"2025-04-18T13:42:21.685253Z","shell.execute_reply":"2025-04-18T13:43:07.814857Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.load_state_dict(torch.load(\"best_model.pth\"))\nevaluate_model(model, test_loader, DEVICE)\nvisualize_predictions(model, test_loader, DEVICE, num_samples=5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T13:31:35.058973Z","iopub.execute_input":"2025-04-18T13:31:35.059278Z","iopub.status.idle":"2025-04-18T13:32:17.835901Z","shell.execute_reply.started":"2025-04-18T13:31:35.059256Z","shell.execute_reply":"2025-04-18T13:32:17.835143Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}